{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"processed_data.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x_train', 'y_train', 'x_valid', 'y_valid', 'x_test', 'y_test']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153582, 47)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['x_train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153582, 46)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['y_train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression factor: 4.6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 40)                1880      \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 40)                840       \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 46)                1886      \n",
      "=================================================================\n",
      "Total params: 5,856\n",
      "Trainable params: 5,856\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_dim = data['x_train'].shape[1]-1\n",
    "encoding_dim = 10\n",
    "\n",
    "compression_factor = float(input_dim) / encoding_dim\n",
    "print(\"Compression factor: %s\" % compression_factor)\n",
    "\n",
    "autoencoder = tf.keras.Sequential([\n",
    "    # Encoder Layers\n",
    "    tf.keras.layers.Dense(4 * encoding_dim, input_shape=(input_dim,), activation='relu'),\n",
    "    tf.keras.layers.Dense(2 * encoding_dim, activation='relu'),\n",
    "    tf.keras.layers.Dense(encoding_dim, activation='relu'),\n",
    "    # Decoder Layers\n",
    "    tf.keras.layers.Dense(2 * encoding_dim, activation='relu'),\n",
    "    tf.keras.layers.Dense(4 * encoding_dim, activation='relu'),\n",
    "    tf.keras.layers.Dense(input_dim, activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 46)                0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 40)                1880      \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 20)                820       \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 2,910\n",
      "Trainable params: 2,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_img = tf.keras.layers.Input(shape=(input_dim,))\n",
    "encoder_layer1 = autoencoder.layers[0]\n",
    "encoder_layer2 = autoencoder.layers[1]\n",
    "encoder_layer3 = autoencoder.layers[2]\n",
    "encoder = tf.keras.Model(input_img, encoder_layer3(encoder_layer2(encoder_layer1(input_img))))\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 153582 samples, validate on 19527 samples\n",
      "Epoch 1/10\n",
      "153582/153582 [==============================] - 11s 74us/step - loss: 0.7258 - val_loss: 0.6539\n",
      "Epoch 2/10\n",
      "153582/153582 [==============================] - 10s 64us/step - loss: 0.6667 - val_loss: 0.6419\n",
      "Epoch 3/10\n",
      "153582/153582 [==============================] - 10s 64us/step - loss: 0.6586 - val_loss: 0.6353\n",
      "Epoch 4/10\n",
      "153582/153582 [==============================] - 10s 65us/step - loss: 0.6542 - val_loss: 0.6318\n",
      "Epoch 5/10\n",
      "153582/153582 [==============================] - 10s 64us/step - loss: 0.6505 - val_loss: 0.6292\n",
      "Epoch 6/10\n",
      "153582/153582 [==============================] - 10s 68us/step - loss: 0.6478 - val_loss: 0.6272\n",
      "Epoch 7/10\n",
      "153582/153582 [==============================] - 11s 75us/step - loss: 0.6456 - val_loss: 0.6243\n",
      "Epoch 8/10\n",
      "153582/153582 [==============================] - 13s 84us/step - loss: 0.6435 - val_loss: 0.6217\n",
      "Epoch 9/10\n",
      "153582/153582 [==============================] - 11s 73us/step - loss: 0.6419 - val_loss: 0.6201\n",
      "Epoch 10/10\n",
      "153582/153582 [==============================] - 11s 68us/step - loss: 0.6407 - val_loss: 0.6194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x12cce6748>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "autoencoder.fit(data['x_train'][:,:][:,:-1], data['x_train'][:,:][:,:-1],\n",
    "                epochs=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(data['x_valid'][:,:][:,:-1], data['x_valid'][:,:][:,:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedded(not_embedded_data):\n",
    "    embedded = encoder.predict(not_embedded_data[:,:][:,:-1])\n",
    "    return np.append(embedded, not_embedded_data[:][:,-1].reshape(embedded.shape[0], 1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_e = get_embedded(data['x_train'])\n",
    "y_train_e = encoder.predict(data['y_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid_e = get_embedded(data['x_valid'])\n",
    "y_valid_e = encoder.predict(data['y_valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_e = get_embedded(data['x_test'])\n",
    "y_test_e = encoder.predict(data['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"embedded_data.npz\", x_train_e=x_train_e, y_train_e=y_train_e, \n",
    "         x_valid_e= x_valid_e, y_valid_e=y_valid_e, x_test_e=x_test_e, y_test_e=y_test_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs234_project",
   "language": "python",
   "name": "cs234_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
